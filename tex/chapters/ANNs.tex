\chapter{Artificial Neural Networks}
\label{ch:Artificial_Neural_Networks}
%\section{Introduction}
%\label{sec:AAN_intro}
%A neural network is an interconnected assembly of simple processing elements, units or nodes, whose functionality is loosely based on the animal neuron. The processing ability of the network is stored in the interunit connection strengths, or weights, obtained by a process of adaptation to, or learning from, a set of training patterns.

\acfp{ANN} are computational systems which elaborate information in a way that is loosely inspired by the operation of biological neural networks (animal brains).
Biological networks are superior in performance to computers and extremely more efficient in difficult tasks such as classification (e.g. image recognition) and prediction (e.g. pattern recognition).
The underlying idea is to copy some of their mechanisms and exploit them for computational applications.
These systems are intrinsically parallel in operation, do not require specific programming to operate, and modify their behavior through a learning process to improve their accuracy in a certain task.

Mathematically speaking, \acsp{ANN} are a collection of nodes, each one of them elaborates the information and is somehow connected to the other.
Artificial networks can be either simulated on computers or physically built on hardware designed ad hoc.
At this time, \acsp{ANN} are mainly implemented by simulations, however the technological progress is withheld by limitation in computing power and efficiency.
Training a complex artificial neural network with computers at the state of art might take even weeks.
Thus, with the aim of improving performance from simulated networks, research on hardware architectures is surging: digital, analog, electrical, and optical devices are being developed.

\section{History}
\label{sec:History}
It is widely acknowledged that the opening work of this research field was made in 1943 by Warren McCulloch and Walter Pitts, a neurophysiologist and a mathematician respectively.
In their research work, they described the operating mechanism of biological neurons by modeling a simple electronic circuit \cite{McCulloch1943}.

The following important work was made by Donald O. Hebb, who hypothesized the neural plasticity in 1949 \cite{hebb1949organization}.
He pointed out the fact that neural pathways are strengthened each time they are used, a concept known as \textit{Hebbian learning}.

During the late 1950s and the early 1960s, as computers became more powerful, many promising works were published.
Some simulated operation of artificial networks on calculators, e.g. Farley and Clark \cite{Farley1954} and Rochester \cite{Rochester1956}.
Other produced circuitry that implemented on hardware such networks, e.g. Rosenblatt \cite{frank1957perceptron,Rosenblatt1958}.
However, despite the early successes of neural networks, the traditional computing architecture (von Neumann architecture) was chosen as the preferred computing architecture.
%As a result, funding and therefore also research diminished drastically in the following decades.

The reason why this happened, probably, was due to several concurring facts.
First of all, in the same time period (1969) a research paper by Minksi and Papert \cite{minski1969perceptrons}, which identified two important problems.
The basic perceptron was not able to execute the \ac{XOR} operation, unlike the logical circuits at the base of von Neumann architecture.
Moreover, the research stated the fact that more complex networks such as multiple- or deep-layered networks were impossible to train due to the vanishing gradient problem. %(at that time) because of the lack of adequate processing power.

%who discovered two key issues with the computational machines that processed neural networks.
%The first was that basic perceptrons were incapable of processing the exclusive-or circuit.
%The second was that computers didn't have enough processing power to effectively handle the work required by large neural networks.
%in the same time period a research paper wrongly suggested that there could not be any multiple-layered neural network.

In addition to this research, the early successes of some works on neural networks pointed to an overestimation of the artificial neural networks potential, also held back by the technological capacity of the time.
Finally, important questions of philosophical nature came to light, such as the fear fueled debate on the impact on our society of a class of computers able to think.
This very controversy, i.e. the \ac{AI} problem, is discussed still today \cite{stanford.edu}.

Sometime during the 1980s the interest for this computing method was reinvigorated.
The main stimulation was probably given by a number of works which suggested methods to implement multi-layered networks by distributing pattern recognition errors through all the layers in the network.
This method is now called \textit{backpropagation}.

In today's research and technology, artificial neural networks are used in numerous applications.
However, the development is made slowly, due to technological limitation in computational power of present processors.

\section{Basis of Neural Networks}
\label{sec:Basis_of_Neural_Networks}

A neural network is a collection of processing elements, or nodes, interconnected in an arbitrary topology.
From its input nodes, the network accepts information, which will propagate into the inner nodes through the interconnections and will get elaborated at each node.
At the end of the network, there will be a number of output nodes, with the task of reading a portion of the inner nodes.
The inner nodes are also called hidden, because they are not meant to be accessible to the external world.
A generic scheme of such network is shown in \autoref{fig:generic_NN} \vpageref{fig:generic_NN}.

\begin{figure}[ht]
	\centering
	\input{tikz/GenericNN.tex}
	\caption{	Generic scheme of a neural network. %
						Triangles (red) are input nodes, circles (grey) are inner nodes, and squares (blue) are output nodes. %
						Interconnections among nodes are represented by arrows: %
						continuous when both elements are drawn, and dotted otherwise.
						%						I chose a non-standard representation to emphasize the nonlinear nodes, which will use a nonlinear activation function. %
						}
	\label{fig:generic_NN}
\end{figure}

Nodes can all implement the same function or behave differntly, depending on the type of neural network.
%Each node can operate in the same way of the others or in a completely different manner, depending on the type of neural network.
The operation of nodes resembles that of animal neurons: various input gets collected and elaborated together to obtain an output, which will become one of the many inputs for subsequent neurons/nodes.
Specifically, the most used model for neurons is the McCulloch–Pitts (MCP) neuron.
It is divided into two parts, as shown in \autoref{fig:generic_node}: the first part is a weighted sum of the inputs, while the second part is given by the so called activation function.
\newpage
\begin{figure}[ht]
	\centering
	\input{tikz/GenericNode.tex}
	\caption{Generic node representation. $x$-values are inputs, $y$-values are outputs, $w_0$ is the bias.}
	\label{fig:generic_node}
\end{figure}
The node is described mathematically by \cref{eq:Generic_node_function}
\begin{equation}
y = f_a \left(  w_0 + \sum_{i=1}^{n} w_i x_i \right),
\label{eq:Generic_node_function}
\end{equation}
where $f_a$ is the activations function, evaluated on the sum of the input $x_i$ weighted with $w_i$, plus a bias $w_0$.

Each node accepts values at its inputs and produces an output accordingly.
However, in addition to the input, the output depends also on the node's parameters: the weights and the bias, which are usually changed outside the operative phase of the neural network (see \autoref{sec:Working_Principles_of_ANNs}).

Moreover it is mandatory for the activation function $f_a\left(\cdot\right)$ to be nonlinear, because otherwise a collection of nodes will result in just a weighted sum of its inputs.
Two examples of nonlinear function are shown below in \autoref{fig:activation_function_examples}.

\begin{figure}[ht]
	\begin{subfigure}[b]{0.49\textwidth}
		\centering
		\input{tikz/HeavisideThetaFunction.tex}
		\caption{}
		\label{fig:activation_function_example_1}
  \end{subfigure}
  \begin{subfigure}[b]{0.49\textwidth}
  		\centering
		\input{tikz/LogisticFunction.tex}
		\caption{}
		\label{fig:activation_function_example_2}
  \end{subfigure}
  \caption{Examples of activation function: (\ref{fig:activation_function_example_1}) is the well-known step function, or Heaviside $\Theta$, (\ref{fig:activation_function_example_2}) depicts a few functions from the family of the Logistic functions.}
  	\label{fig:activation_function_examples}
\end{figure}

One can distinguish at least three type of nodes in every neural network: input, inner/hidden, and output nodes.
Input nodes take one input value, from the outside of the neural network, and pass it on to the inner nodes unchanged.
Inner/hidden nodes take many inputs and generate an output through the activation function.
Output nodes, similarly to input nodes, take one input value, from the inside of the \acs{ANN}, and pass it on to the outside.

\subsection*{Standard Representation}
%This is not the orthodox description, but I claim that it is more consistent than the standard representation with the idea of functional \textit{black box}, in which input and output are the only visible nodes, while the other are hidden inside.
The way I depicted a generic neuromorphic network in \autoref{fig:generic_NN} is not the standard representation used in books and research papers.
The main difference is that usually weights are commonly represented on the connection between the nodes, which are then designated to apply only the activation function.
Moreover the input layer is linear as it feeds the inner nodes with the input data, while the output layer is actually given by the last nonlinear layer of the inner nodes.
A generic network is shown in \autoref{fig:standardNNdesc}.

\begin{figure}[ht]
	\begin{subfigure}[b]{0.49\textwidth}
		\centering
		\input{tikz/standardNNdesc.tex}
		\caption{Standard way of representing networks}
		\label{fig:standardNNdesc}
  \end{subfigure}
  \begin{subfigure}[b]{0.49\textwidth}
  		\centering
		\input{tikz/BlackBoxNN.tex}
		\caption{Representation of the black-box concept}
		\label{fig:black_box_NN}
  \end{subfigure}
  \caption{}
  	\label{fig:description_comparison}
\end{figure}

On the contrary, I consider the inner nodes as the only place where any kind of elaboration on the data happens.
Inner nodes have a number of inputs, which are weighted and summed together to be entered as argument in the activation function.
This leads to a natural separation between input/output nodes, which acquire the task of providing data from/to the outside, and inner nodes, which is where the activation function and/or the weighted sum are carried out.

This non-standard description, moreover, is consistent with the idea of functional \textit{black box}, in which input and output are the only visible nodes, while the other are hidden inside, as shown in \autoref{fig:generic_NN}.
%Therefore I can easily distinguish the nodes which will use a nonlinear activation function.
%Questa non è la visione standard/ortodossa, ma è consistente con un'idea di 'black box' in cui gli input e output sono gli unici nodi visibili. mentre gli altri sono all'interno della scatola nera.

\subsection{Applications of ANNs}
\label{ssec:Applications_of_ANNs}
Conventional computers are extremely fast and efficient in executing simple algebraic tasks and they can perform more complex activities if provided with the correct series of instructions.
Hence algorithms can solve arbitrary difficult problems, provided that the necessary steps are know.

Artificial neural networks take a different path in the solution of a given problem.
\acsp{ANN} cannot be programmed, but they learn from the examples that are provided to them.
Then they exploit their internal complexity to minimize the error and hence automatically solve the problem.
After a network has been prepared, it is able to operate much faster than the complex algorithms on conventional computers.

\acsp{ANN} have proven to be extremely good at recognize patterns, which can be used to solve problems in several classes.
For example, classification problems are solved by the recognition of attributes of the input element.
Likewise, clustering is obtained when a sequence of examples is grouped according to their features.
Moreover, regression analysis and time series prediction can be obtained, when a sequence of data is fed to the network.
% Regression: Predicting a continuous variable\\
% Classification: Predicting a variable with finite possible values\\
% Clustering: Grouping data\\
% https://cs.stackexchange.com/questions/58131/are-neural-networks-a-type-of-reinforcement-learning-or-are-they-different

\section{Working Principles of ANNs}
\label{sec:Working_Principles_of_ANNs}
Because of its topology, each neural network will behave in a different manner from other neural networks with diverse, or even similar, arrangements of nodes.
Moreover the same neural network will perform a certain task better or worse also depending on how inputs are weighted at each hidden node, and normally those parameters are initialized with a random value at the creation of the network.
For this reason, before a neural network is considered ready to perform a task, it usually must go through three training stages: learning phase, validation phase, and testing phase.
Every one of these stages is meant to prepare the network to work as required from the designer.

\subsection{Learning Process}
\label{ssec:Learning_Process}
During the learning process the neural network is run on a set of known inputs $x$, each paired with its correct answer $y$, or target, in a second set of data.
The neural network will produce at the output a third set $\hat{y}$, which should be as close as possible to the correct answers, when the network works properly.
%However this happens rarely, if ever, and a change in the way data is elaborated becomes necessary.
%The usual \ref{} way is to keep the same topology, but tweak the weights that connect the hidden nodes together.
%On account of this need, one have to quantify the distance of the predicted result of the artificial neural network from the correct answer.
%This is made by means of the loss function.
Typically weights among nodes are initialized randomly and the distance of the network outcome from the target function is measured through a loss function.
Then weights are modified in order to decrease the loss function to its lowest possible value. %up to a tolerance limit is achieved.

\subsubsection{Loss function}
\label{sssec:Loss_function}
The loss function $L(y, \hat{y})$ evaluates the difference between the predicted and the correct answer.
Usually, this quantity is linked to the geometrical distance between the predicted output and the target $\left| \hat{y}-y \right|$.

The most common loss function is the \acfi{MSE}.
Assuming to have an input set of $N$ examples paired with the same number of targets, and that the outputs and the targets are composed by $C$ values, or classes, the function becomes:
\begin{equation}
	L(y, \hat{y}) = f_{MSE}(y, \hat{y}) = \frac{1}{N} \sum_{n=1}^N \sum_{i=1}^C \left( \hat{y}_{n,i} - y_{n,i} \right)^2,
\end{equation}
where each example in the set is subtracted to its target and then squared.
Finally the mean of all squares gives the expected result.

Another commonly used function is the \acfi{CEL} (also known as negative log likelihood),
\begin{equation}
	L(y, \hat{y}) = f_{CEL}(y, \hat{y}) = - \frac{1}{N} \sum_{n=1}^N \sum_{i=1}^C y_{n,i} \log \left( \hat{y}_{n,i} \right),
\end{equation}
which expects positive values at the input.
Hence the error $-y\log \left( \hat{y} \right)$, quantified for each element in each example, is always a positive number.
The mean over all examples in the set returns the results.

Alternatively, variations of the previous methods are given by taking the sum of the examples in place of the mean, or by calculating a loss function for each example instead of evaluating it for the whole set.

Depending on the class of the problem, e.g. classification or image recognition, a different loss function is chosen.
In fact, since the loss function drives the weights update process, it is important to choose the correct one.

\subsubsection{Weights Update Process}
\label{sssec:Weights_Update_Process}

The weights update process is a difficult task, and probably the most computationally expensive one in running a neural network.
There is a variety of methods to chose from, depending on the type of artificial network and the resources available.

A widely used algorithm is the gradient descent, from its most simple version to more complex variations such as \acfi{SGD}.
This method updates the weights by subtracting a value proportional to the gradient of the loss function in respect to the weights themselves times a positive factor called \textit{learning rate}, as shown below.
\begin{equation}
	\left.w_i\right|_{n+1} = \left.w_i\right|_n - lr \cdot \frac{\partial L}{\partial \left.w_i\right|_n}
\end{equation}
where $\left.w_i\right|_{n}$ are the current weights, $lr$ is the learning rate, $\dfrac{\partial L}{\partial \left.w_i\right|_n}$ is the first derivative of the loss function in respect to the i-th weight at the current step, and $\left.w_i\right|_{n+1}$ are the updated weights.
%Hence it is necessary to calculate the gradient $\bigtriangledown_w L$.
This method is equivalent to minimize the error on the loss function, by following the gradient $\bigtriangledown_w L$.
This vector lives in the multidimensional space of the loss function $L:\mathbb{R}^W \mapsto \mathbb{R}$, where $W$ is the total number of parameters in the network.

The most used algorithm is called \textit{backpropagation}: it computes the first derivative of the loss function $L$ in respect to all the parameters of the network, the weights, starting from the end of the artificial network and going backward toward the input, hence the name backpropagation.
Since the number of connections between nodes might be even order of magnitude bigger than the number of nodes, it is simple to understand how large networks are computationally expensive to train.

In early days, this algorithm was used together with the Logistic activation function.
Due to the saturating behavior of the function, the gradient is repeatedly multiplied by small values at each layer.
Hence, the effect of backpropagation becomes negligible for the first layer on deep networks
This problem is known as \textit{vanishing gradient} problem.
Thanks to the introduction of non saturating activation functions, the training of deep neural network has become gradually possible \cite{krizhevsky2012imagenet}.
%\paragraph{Other types of learning processes} are used, e.g. unsupervised/reinforced.

\subsection{Validation Process}
\label{ssec:Validation_Process}
The validation process is carried out at the same time of the training process and consists on testing the neural network on a new set of examples.
Differently from the learning process, during validation the output predicted by the network are compared to the examples, but the weights are not updated.
Instead, the loss function is used as a control parameter to prevent overfitting

Overfitting is the phenomenon in which a neural network recognizes specific features of the samples instead of the more general ones.
It occurs when the network is trained over and over on the same set of data.
Since the specific features are the ones that characterize precisely the test dataset, they should not characterize other dataset.
Therefore, by periodically testing the network on a novel set, i.e. the validation set which is different from the training set, one can avoid or at least reduce the problem.

The validation process happens repeatedly throughout the training process, more or less often, depending on the resources available and the size of the dataset.

\subsection{Testing Process}
\label{ssec:Testing_Process}
At the end of the training and validation processes, there is the process of testing the artificial neural network.
The network is tested on a new set of data, the test data.
This time the predicted outputs are compared to the correct answers, but no weights are changed.
Instead, an overall value of the correctness is evaluated and it is often expressed in percentage.

\begin{figure}[htbp]
	\centering
	\input{tikz/LVTcurves.tex}
	\caption{The learning curves are the value of the loss function, or criterion, as a function of the training iterations.
	Both the validation and the test error are usually higher than the errors on the training set.
	Sometimes, to avoid overfitting, the training procedure is stopped at a minimum of the validation learning curve \cite{duda2012pattern}.
	}
	\label{fig:LVTcurves}
\end{figure}

\subsection{Datasets}
\label{ssec:Datasets}
Creating a dataset and splitting it into subsets is another problem to deal with.
It is not so simple and straightforward as it appears.
For example a dataset which is too big will lead to a longer training time for the network, whereas a too little set will cause a poor training.

The most naive division is in three equal parts, since three are the phases of preparation for any artificial neural network.
However, as shown later in \autoref{ssec:PyDataset}, when the resources dictates otherwise, other subdivision can be implemented.
In my case, the decision was to follow the suggestions of the authors of the dataset and divide the examples into a training set and a test set only, with a ratio between the two close to 50\%.

\section{Feedforward NN}
\label{sec:Feedforward_NN}

The first and most simple type of neural network is called Feedforward.
In this kind of neural network, nodes are divided into groups called \textit{layers}.
A layer is a collection of nodes that accepts inputs from a preceding group and generate as many outputs as the number of nodes in the layer.
Each layer of a Feedforward neural network is connected in series with the others, except for the input layer at the beginning and the output layer at the end.
As for the single nodes, the inner layer are called hidden, because usually not accessible.

The information travels from the input to the output and gets elaborated from each hidden layer: there are neither connection between nodes of the same layer, nor loops or feedback between layers.
%Depending on the topology of the network, there might be more or less layers, each composed by the same or a different number of nodes.
The number of hidden layers and the number of nodes they contain depends on the network topology.
Moreover the connection between the layers might be complete, i.e. each node in the layer accepts each input of the preceding layer, in that case the layer is said to be \textit{fully connected}, or sparse as in the case of convolutional layers (see \autoref{par:Convolutional}).

\subsection{Perceptron}
\label{ssec:Perceptron}

The most naive topology of a Feedforward neural network is given by the so called \textit{Perceptron}.
The Perceptron dates back to the 1957, when the homonym \textit{Perceptron algorithm} was software implemented by Frank Rosenblatt on a computer (IBM 704) and only subsequently in hardware as the \textit{Mark 1 perceptron} \cite{frank1957perceptron,Rosenblatt1958}.
The graph of a generic (single layer) perceptron \acs{ANN} is shown in \autoref{fig:Perceptron}.

\begin{figure}[ht]
	\centering
	\input{tikz/PerceptronNN.tex}
	\caption{%
		Perceptron type neural network: in this representation the perceptron has $n$ inputs and $m$ outputs as well as a hidden layer with $m$ nodes. %
%		Colors, shape and styles are the same as in \autoref{fig:generic_NN} \vpageref{fig:generic_NN}.%
		}
	\label{fig:Perceptron}
\end{figure}

By adding more than one hidden perceptron layer to the neural network, one obtain the so called \acfi{MLP}.
This allows for more computational complexity, e.g. \acs{MLP} can solve the \acs{XOR} problem, whereas single layer perceptron cannot \ref{}.
When the number of hidden layers is more than two, the network is called \textit{deep}.
A deep \acs{MLP} is shown in \autoref{fig:deepMLP}.

\begin{figure}[ht]
	\centering
	\input{tikz/MLPNN.tex}
	\caption{	Deep \acf{MLP}, fully connected.}
	\label{fig:deepMLP}
\end{figure}

In principle any shape is possible, i.e. each layer could have a different number of nodes, however often the layers at the beginning are wider than the layer at the end of the network (see following section).
Moreover, in literature with the term perceptron one almost always refers to fully connected feedforward networks \ref{}.

\subsection{Other Feedforward NNs}
\label{ssec:Other_Feedforward_NNs}

Feedforward neural networks are a large family that includes many other types besides the perceptron one.
A few names are autoencoder, time delay, and convolutional neural networks.
Autoencoders \acsp{ANN} are feedforward networks with the same number of input and output nodes, with the purpose of reconstructing its own inputs.
For this reason autoencoders employ unsupervised learning.
Time delay networks have a feedforward structure and their purpose is to analyze patterns in

\subsubsection{Convolutional Neural Networks}
\label{par:Convolutional}
\acp{CNN} are inspired to the visual cortex, in which neurons are not fully connected all the inputs but only to a restricted region.
\aclp{CNN} are a type of feedforward network conceived to recognize images without being misled by distortions such as translation, skewing, or scaling.
Its input is often represented as a 2D matrix, instead of a 1D vector.
This kind of network is usually composed by many layers: the most recurring is prevalent the convolutional one, but other types can be mixed together too.

\begin{figure}[ht]
	\centering
	\input{tikz/ConvNN.tex}
	\caption{%
		Pictorial representation of a layer of a convolutional supernode.
		Several supernodes might be placed side by side to form a convolutional layer.
		Each node acts on a restricted region of the inputs: in this examples a $3\times 3$ region.
		}
	\label{fig:convolutionalNN}
\end{figure}

This layer performs a two-dimensional convolution over the input matrix of a second 2D matrix of weights, called \textit{feature map}.
Thus, each node of the layer operates on a restricted region to understand if a feature is present or not.
The operating regions are commonly overlapping and the feature map is shared among the nodes in the same layer.
Due to the specific operation of convolutional layers, the number of nodes per layer decreased with each layer.

\aclp{CNN} are nowadays widely used in image recognition with outstanding results and they improve with a steady pace.
A technological application of this kind of network is the real time recognition of obstacles in a vehicle path, for safety and automation purposes in the automotive industry.

\subsection{Other Types of NNs}
\label{ssec:Other_Types_of_NNs}
By changing the topology of the nodes distribution and their connections, one obtain other networks that cannot be catalogued under the class of feedforward networks.
Moreover, those different types of network are not a niche, but they are widely studied as a different approaches to the same or additional problems.

\subsubsection{Recurrent NN}
\label{sssec:Recurrent_NN}
\acp{RNN} are a kind of network in which a portion of the input of nodes depends on the (past) output of the same nodes or nodes of subsequent layers.
That is information does not propagates only forward like in the feedforward networks, but can propagate also backward, for example in loops or in feedbacks.

\begin{figure}[ht]
	\centering
	\input{tikz/RecurrentNN.tex}
	\caption{%
		Representation of a recurrent node.
		One of the inputs is given by the output itself.
		This output to input connection could be mediated by a delay device, so that for example the output at $t-1$ becomes the input at $t$.
		Depending on the structure of the network, there might be recurrent nodes and/or recurrent groups of nodes, i.e. loops.
		}
	\label{fig:RecurrentNN}
\end{figure}

Recurrent networks have found greatest use in time series analysis and prediction \cite{duda2012pattern}.
However often recurrent type of networks are employed to obtain the same classification of feedforward ones.
In this case, the former are equivalent to the latter, if ``unfolded'' in time.
That is the expansion of the recurrent architecture in time is the same as the topology of the feedforward one in space.

\subsubsection{Reservoir NN}
\label{sssec:Reservoir_NN}
Reservoir neural networks, or \ac{RC}, differ from feedforward and recurrent networks in the learning approach.
In fact, the topology of a reservoir network could be exactly the same as that of a deep multi-layer perceptron or that of a recurrent network.
However, the reservoir computing differs in approach in respect to deep learning.
It claims that it is not necessary to learn all the weights of the network, as in deep learning, but it is sufficient to train only the last (perceptron) layer of the network.

\begin{figure}[ht]
	\centering
	\input{tikz/ReservoirNN.tex}
	\caption{A reservoir NN is topologically equivalent to deep networks. However only the last layer is trained. In this picture the trained node are represented outside the box, while those inside are initialized with random weights which are then left unchanged.}
	\label{fig:reservoirNN}
\end{figure}

\noindent This kind of networks, then, can be trained much faster than their respective counterparts, i.e. feedforward and recurrent.
The question over which training method is more efficient is still debated and literature does not provide clear answers yet.

%\subsubsection{Modular NN}
%\label{sec:Modular_NN}

%\subsubsection{Spiking NN}
%\label{sec:Spiking_NN}
%Spiking artificial networks are the most different kind in respect to all the other networks until now described.
%In this class of ANNs, information is not coded only in the intensity of the signal, but also in the rate of signals, e.g. a high value will be encoded as a signal with high repetition rate, whereas a low value as a signal with low repetition rate.
%This way of encoding information is more alike the mechanism of biological neural networks, such as our brain \ref{}.
%
%\vspace{1em}
%\noindent LOOK INTO other type of neuron model: Hodgkin–Huxley (H-H) model\\
%\url{ https://en.wikipedia.org/wiki/Binding_neuron }

%\section{Real-Life Examples}
%\label{sec:Real-Life_Examples}
%\noindent\uppercase{\large{? Should I keep this section ?}}
%\normalsize

\section{ANN Simulation}
\label{sec:ANN_Simulation}
In the field of artificial neural network simulation, there are several platforms that are independently developed.
Among them there are TensorFlow, Theano, Caffe, Keras, Torch, and PyTorch.
Unfortunately, each one of them have its strength and weakness, therefore the choice of the framework becomes very difficult.

To make a choice, the key factors considered were the language used, the features, the flexibility, and the level of diffusion of the framework in the machine learning community.
The language used is a determining factor, because it takes time to learn the peculiarities of a library written for a known language, but even more time to learn to use an unknown programming language.
However also the features and the flexibility in the implementation are important traits, on account of the fact that any feature that is not natively implemented needs new coding.
In turn, it is difficult to integrate new coding if the framework is not flexible enough to accommodate extensions or custom definitions.
Last, but not least, it is easier to find support for a widespread framework in respect to a limitedly used one.
In regards to this, \autoref{fig:GoogleTrendsPyTorch} shows the number of internet searches for some frameworks in the past few years.

In light of the facts above, PyTorch was chosen as framework.
PyTorch is an open source machine learning library for python, which development has started only recently and it is based upon the older framework Torch  \cite{PyTorch.org}.
It provides a high-level platform for the deep learning ecosystem and integrates acceleration libraries that allow fast and lean operation, both on common \acsp{CPU} and \acsp{GPU}.
It is based on a backpropagation algorithm called \textit{Reverse-mode auto-differentiation}, which allows versatile execution.

To summarize, the library was chosen for its language, its flexibility, and the growing interest for it within the machine learning community.
Nevertheless, its features make it a very powerful framework. However, considering the need to keep the simulated system as simple as possible, this last characteristic slipped in the background.
The need to simulate a simple network comes from the fact that the ultimate goal of this project is to implement an \acs{ANN} with a (photonic) hardware architecture.

\begin{figure}[htbp]
	\centering
	\input{tikz/GoogleTrendsPyTorch.tex}
	\caption{Google Search statistics for different keywords in the \textit{machine learning and artificial intelligence} field.
		Numbers represent search interest relative to the highest point on the chart for the given region and time.
		A value of 100 is the peak popularity for the term.}
	\label{fig:GoogleTrendsPyTorch}
\end{figure}

%The resources and the time available allowed me to implement physically only the activation function of one node.
%Hence, to test this hardware implementation as I will show in \autoref{sec:Test_of_a_Trained ANN} of \autoref{ch:experiments}, I had first to simulate and train \textit{offline} a specific neural network.
%To do so, I chose a programming language, \textit{Python}, and a library, \textit{PyTorch}, which helped me in this task.

\subsection{PyTorch}
\label{ssec:PyTorch}
PyTorch is a Python package which provides a powerful framework for deep learning.
It is versatile in the sense that allow customizations at almost every level of operation.
For the purposes of this work, a neural network implemented in PyTorch is composed by the definition of three main components and a few lines of code to implement the operation.

The most important part of the network is the so called \textit{model}, which defines the topology of the network by setting parameters such as the number of nodes in each layer and the connections among them.
Moreover, it defines also the activation function for each node, separately or in groups.
The activation function can be coded from scratch, but can also be one of the functions provided by the library or a composition of them.
While the first offers almost unlimited flexibility, the second choice consents to exploit the functions already given.
The second option is the best choice, if the needs of the task support it, because it allows to save much time.

Another important part of the network is the so called \textit{criterion}, which is nothing else than the loss function.
The set of functions provided by PyTorch can accommodate almost any necessity.
Moreover, their operation can usually be adjusted with some internal parameters.

Similarly to the criterion, the last piece of the system is given by the \textit{optimizer}.
Optimizers are a class of algorithms that provides the optimization of the weights during the learning phase.
Most commonly used methods are already supported and they provide parameters to fine tune their execution.

Following the official tutorials and the immense package documentation, I implemented a fully connected \acf{MLP} model and then tested it with randomly generated numbers until its operation seemed correct.
The code that I implemented allows to change the overall structure of the network with some parameters (see \autoref{ssec:Simulated_ANN_operation})
The optimizer chosen is called \acfi{SGD}, which is parametrized just by the learning rate, at least in its vanilla implementation.
The criterion used initially was the mean square error, however it was eventually replaced by the \acfi{CEL}, which is more suited to the classification task.

\subsection{Dataset}
\label{ssec:PyDataset}
Initial tests and trials on artificial neural networks are often made by using randomly generated sets of numbers.
However, once the system has been successfully set up, to compare different working parameters such as number of nodes and number of layers, a common standardized dataset should be employed.
Moreover in this way, it is possible to compare implementations belonging to other research groups.

Again, the need to keep the system as simple as possible, drove my attention towards datasets of middle to small sizes.
With the help of the \textit{UC Irvine Machine Learning Repository} \cite{UCIMLR}, I selected one with a bit less than a thousand entries.
The dataset is called \textit{Connectionist Bench (Vowel Recognition - Deterding Data) Data Set}.
It is composed by \num{990} entries of \num{10} attributes, i.e. input values, grouped in \num{11} classes.

Each entry is a vector of \num{10} real numbers plus an integer number between \num{0} and \num{10}.
In view of the fact the proposed activation function is a real-positive-valued function (see \autoref{sec:Characterization_of_the_Activation_Function}), I renormalized the database.
The normalization is independently applied to each one of the attributes in such a way that is described by a real number in $[0,1]$.
The normalization is applied before the dataset is divided in the learning and testing examples.

The authors suggest to divide the dataset a learning set of \num{528} entries and a testing set of \num{462} entries.
Since the number of entries is low, compared to other datasets, the validation set is not define.
In this case, the test set is used as validation instead too.

\subsection{Simulated ANN operation}
\label{ssec:Simulated_ANN_operation}
The model that I defined allows some changes with the simple definition of a few parameters.
Specifically, the parameters cover the number of input and ouptut nodes, the number of hidden layer, and the number of nodes in each hidden layer.
Whereas the number of input and output nodes is defined by the problem, i.e. the dataset, the other are free parameters that can
Another degree of freedom that I implemented is whether the last hidden layer applies the nonlinear activation function or just the weighted sum, since I observed that many network in the tutorials were built this way.
The scheme of the network is shown in \autoref{fig:ANN_model}.

\begin{figure}[htbp]
	\centering
	\input{tikz/PT_MLP.tex}
	\caption{Topology of the model implemented in PyTorch. The number of input ($D_{in}$) ad output nodes ($D_{out}$), as well as the number of nodes in the last hidden layer is determined by the dataset.
	The number of nodes ($D_{H}$) in the other hidden layers and the number of hidden layers itself ($n_{H}$) is governed by a parameter.}
	\label{fig:ANN_model}
\end{figure}

The choice of the structure of the neural network is purely heuristic, since up to now no satisfactory method has been proposed in literature.
However, given the problem (dataset), at least the input and output layer have a fixed amount of nodes.
Specifically, the input nodes are \num{10}, the number of attributes, while the output nodes are \num{11}, the number of classes.

Using the chosen dataset, I tested the neural network operation on the model defined before, with two different kinds of activation function.
Initially I implemented a \acfi{ReLU} and a \textit{Logistic} (sigmoid) activation functions.
The \acs{ReLU} function is a standard activation function and is defined as follows:
\begin{equation}
f_{ReLU}(x) =
\begin{cases}
	0 & \qquad \mathrm{for}~ x\leq 0\\
	x & \qquad \mathrm{for}~ x\geq 0
\end{cases}~.
\label{eq:relu}
\end{equation}
On the other hand, the Logistic function, which has already been shown in \autoref{fig:activation_function_example_2}, is defined by
\begin{equation}
f_{Logistic}(x) = \frac{1}{1+e^{-k\left(x-x_0\right)}},
\end{equation}
with the parameters $k\in \mathcal{R}^+$ and $x_0\in \mathcal{R}$.
Both functions are widely used in literature, however the \acs{ReLU} function seems to be preferred lately.
I will discuss in \autoref{sec:Test_of_a_Trained ANN} the results of the same network models, with the nonlinear activation function given by the microring resonator.

\subsubsection{Learning}
After the definition of the model, I had to train the networks on the training set.
Since the dataset is small, all the examples are fed into the model, then the overall loss is evaluated, and finally the weights are upgraded.
This method is called \textit{batch} operation; others are \textit{online} operation, which evaluate the loss and change the weights at each example, and \textit{minibatch} operation, which uses a random subset of the full dataset.

Every time the network is trained on the full dataset, an \textit{epoch} is completed.
I trained the models defined above for \num{2000} epochs, in order to observe both the fast and slow dynamics.
For example, smaller networks tend to train faster, because there are less free parameters.
On the other hand, larger networks often train slower, but can obtain better results thanks to their complexity.

Moreover, I defined a different learning rates $l_r$ for each activation function, in order to provide the best parameter for different models but still be able to compare the performance of similar ones.
Specifically the learning rate for the \acs{ReLU} is $l_{r|ReLU} = \num{5e-2}$, while for the Logistic function is $l_{r|Logistic}= \num{5e-3}$

\begin{figure}[htbp]
	\centering
	\input{tikz/Train_evolution.tex}
	\caption{Evolution of the loss criterion (solid lines) throughout the epochs.
		Points represent the values of the loss criterion on the validation dataset, carried out repeatedly during the training.
	}
	\label{fig:PyTorch_learning}
\end{figure}

\autoref{fig:PyTorch_learning} shows the evolution of the loss and the validation of each model during the \num{2000} epochs of training.
From the evolution of the loss function we can see that every model has 


\subsubsection{Collection of results}
Since the number of classes is \num{11}, the percentage of correct answer given a random value is $\sim \SI{9.09}{\percent}$.
Hence, values of correct answers above that mean that the neural network is working.
On the other hand, values around or even below \SI{9.09}{\percent} mean that the current neural network is not working at all.

\autoref{tab:PyResults} collects all the results for the different topologies.
The same shape has been tested with both $f_{ReLU}$ and $f_{Logistic}$ to compare the performance.

\begin{table}[htbp]
	\centering
	\begin{tabular}{c c c c r}
	\toprule
	activation	& no. hidden 	& no. nodes	& other			& Percent\\
	function		& layers 			& per layer	& parameters	& correct\\
	\midrule
	$f_{ReLU}$ 			& 2 & 11 & - & \SI{70}{\percent}\\
	$f_{ReLU}$ 			& 2 & 22 & - & \SI{70}{\percent}\\
	$f_{ReLU}$ 			& 3 & 11 & - & \SI{70}{\percent}\\
	$f_{ReLU}$ 			& 3 & 22 & - & \SI{70}{\percent}\\
	$f_{Logistic}$ 	& 2 & 11 & - & \SI{9}{\percent}\\
	$f_{Logistic}$ 	& 2 & 22 & - & \SI{9}{\percent}\\
	$f_{Logistic}$ 	& 3 & 11 & - & \SI{9}{\percent}\\
	$f_{Logistic}$ 	& 3 & 22 & - & \SI{9}{\percent}\\
	\bottomrule
	\end{tabular}
	\caption{Results of the different activation functions and the several network topologies.
	}
	\label{tab:PyResults}
\end{table}

%+-------------------------+--------+---------+---------+
%|                         | no. of | no.     | percent |
%|       Classifier        | hidden | correct | correct |
%|                         | units  |         |         | 
%+-------------------------+--------+---------+---------+
%| Single-layer perceptron |  -     | 154     | 33      | 
%| Multi-layer perceptron  | 88     | 234     | 51      |
%| Multi-layer perceptron  | 22     | 206     | 45      |
%| Multi-layer perceptron  | 11     | 203     | 44      | 
%| Modified Kanerva Model  | 528    | 231     | 50      |
%| Modified Kanerva Model  | 88     | 197     | 43      | 
%| Radial Basis Function   | 528    | 247     | 53      |
%| Radial Basis Function   | 88     | 220     | 48      | 
%| Gaussian node network   | 528    | 252     | 55      |
%| Gaussian node network   | 88     | 247     | 53      |
%| Gaussian node network   | 22     | 250     | 54      |
%| Gaussian node network   | 11     | 211     | 47      | 
%| Square node network     | 88     | 253     | 55      |
%| Square node network     | 22     | 236     | 51      |
%| Square node network     | 11     | 217     | 50      | 
%| Nearest neighbour       |  -     | 260     | 56      | 
%+-------------------------+--------+---------+---------+